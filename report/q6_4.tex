\section{Gram-Schmidt orthogonalization}

To compare the two algorithms we test several numbers of threads for the same number of data. The figure \ref{fig:gram2} shows the result for the second algorithm, and the figure \ref{fig:gram3} shows the result for the third algorithm.\\

\begin{figure}[!h]
  \begin{center}
         \resizebox{160mm}{!}{\includegraphics{pic/graph_gram2.eps}}
  \end{center}
  \caption{Gram-Schmidt orthogonalization 2 speedup}
  \label{fig:gram2}
\end{figure}

In \ref{fig:gram2} we can see that small matrices do not have any speedup ($10$ and $100$) because of the overhead.
Matrices of $1000\times 1000$ and  $2000\times 2000$ elements have a big speedup for a low number of thread (both have the max speedup for 8 threads, respectively $~3.25$ and $~4.75$), but with more threads the speedup decreases quickly. For the $1000\times 1000$ matrix we see that the speedup goes down below 1, and for $2000\times 2000$ we stay around $1.70$.

Bigger matrices stay around a speedup of 2 for any number of thread.\\

\begin{figure}[!h]
  \begin{center}
         \resizebox{160mm}{!}{\includegraphics{pic/graph_gram3.eps}}
  \end{center}
  \caption{Gram-Schmidt orthogonalization 3 speedup}
  \label{fig:gram3}
\end{figure}

The third algorithm has a better speedup than the second. The $2000\times 2000$ elements matrix reaches a speedup of $~7.5$ with 64 threads. The other big matrices are between $~3.5$ and $~5$ this time, and we do not see any decrease with these matrices. Only the $1000\times 1000$ elements matrix has a really big speedup (10 at the maximum) and decrease quickly just after.\\

The difference is due of the way used to parallelize the algorithm.
In the first place we spawn all the threads inside the main loop.
So at every step we wait for everybody and give new work when everybody has finished.
But in second algorithm, we use locks to ensure that the needed values are calculated and we break the range of the main loop in several subsets to give work to every thread.
So we just wait for one thread and not all. In this case, threads that do not need value from a specific thread can work when the others wait.

