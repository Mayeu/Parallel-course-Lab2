\section{Gram-Schmidt orthogonalization}

To compare the two algorithms we test several numbers of threads for the same number of data. The figure \ref{fig:gram2} shows the result for the second algorithm, and the figure \ref{fig:gram3} shows the result for the third algorithm.\\

\begin{figure}[!h]
  \begin{center}
         \resizebox{160mm}{!}{\includegraphics{pic/graph_gram2.eps}}
  \end{center}
  \caption{Gram-Schmidt orthogonalization 2 speedup}
  \label{fig:gram2}
\end{figure}

In \ref{fig:gram2} we can see that small matrices do not have any speedup ($10$ and $100$) because of the overhead.
Matrices of $1000\times 1000$ and  $2000\times 2000$ elements have a big speedup for a low number of thread (both have the max speedup for 8 threads, respectively $~3.25$ and $~4.75$), but with more threads the speedup decreases quickly. For the $1000\times 1000$ matrix we see that the speedup goes down below 1, and for $2000\times 2000$ we stay around $1.70$.

Bigger matrices stay around a speedup of 2 for any number of thread.\\

\begin{figure}[!h]
  \begin{center}
         \resizebox{160mm}{!}{\includegraphics{pic/graph_gram3.eps}}
  \end{center}
  \caption{Gram-Schmidt orthogonalization 3 speedup}
  \label{fig:gram3}
\end{figure}

The third algorithm has a better speedup than the second. The $2000\times 2000$ elements matrix reaches a speedup of $~7.5$ with 64 threads. The other big matrices are between $~3.5$ and $~5$ this time, and we do not see any decrease with this matrix. Only the $1000\times 1000$ elements matrix has a really big speedup (10 at the maximum) and decreases quickly just after.
